# -*- coding: utf-8 -*-
"""caaico_yamnet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14xLjgYapkmA4Bv0jxQX5wvmYR8HsrQiJ
"""

import librosa
import numpy as np
import time
import threading
import queue
import pickle
import tensorflow as tf
import tensorflow_hub as hub

########### PARAMETERS ###########
# DO NOT MODIFY
# Desired sample rate 16000 Hz
sample_rate = 16000
# Frame length
frame_length = 512

########### AUDIO FILE ###########
# DO NOT MODIFY
# Path to the audio file
audio_file = "audio_aaico_challenge.wav"

# Read the audio file and resample it to the desired sample rate
audio_data, current_sample_rate = librosa.load(
    audio_file,
    sr=sample_rate,
)
audio_data_int16 = (audio_data * 32767).astype(np.int16)
number_of_frames = len(audio_data_int16) // frame_length
audio_data_int16 = audio_data_int16[:number_of_frames * frame_length]
audio_duration = len(audio_data_int16) / sample_rate

########### STREAMING SIMULATION ###########
# DO NOT MODIFY
results = np.zeros(shape=(3, len(audio_data_int16)), dtype=np.int64)
# Detection mask lines are SENT TIME, LABEL, RECEIVE TIME.
buffer = queue.Queue()
start_event = threading.Event()

# Load pre-trained YAMNet model
yamnet_model = hub.load("https://tfhub.dev/google/yamnet/1")

# Mapping YAMNet labels to the specified commands
command_labels = {
    "GALACTIC BATTERY": 47,
    "GALACTIC OXYGEN": 253,
    "GALACTIC TEMPERATURE": 211
}

# Function to check if a command label is present in the YAMNet output
def is_command_detected(yamnet_output, command_label):
    return command_label in yamnet_output

def label_samples(list_samples_id, labels):
    receive_time = time.time_ns()
    results[1][list_samples_id] = labels
    results[2][list_samples_id] = receive_time

def notice_send_samples(list_samples_id):
    send_time = time.time_ns()
    results[0][list_samples_id] = send_time

def emit_data():
    time.sleep(.5)
    print('Start emitting')
    start_event.set()
    for i in range(0, number_of_frames):
        list_samples_id = np.arange(i*frame_length, (i+1)*frame_length)
        time.sleep(frame_length / sample_rate) # Simulate real time
        frame = audio_data_int16[list_samples_id]
        buffer.put(frame)
        notice_send_samples(list_samples_id)
    print('Stop emitting')

def process_data():
    i = 0
    start_event.wait()
    print('Start processing')
    while i != number_of_frames:
        frame = buffer.get()

        # Extract embeddings using YAMNet
        embeddings, _ = yamnet_model(frame)

        # Check if any of the specified commands are present in the embeddings
        labels = [1] * len(frame)
        for command, label in command_labels.items():
            for idx, embedding_label in enumerate(embeddings):
                if is_command_detected(embedding_label, label):
                    labels[idx] = 0  # Command detected

        list_samples_id = np.arange(i * frame_length, (i + 1) * frame_length)
        label_samples(list_samples_id, labels)
        i += 1

    print('Stop processing')
    # Save the list to a file
    with open('results.pkl', 'wb') as file:
        pickle.dump(results, file)

if __name__ == "__main__":
    time_measurement = []

    thread_process = threading.Thread(target=process_data)
    thread_emit = threading.Thread(target=emit_data)

    thread_process.start()
    thread_emit.start()